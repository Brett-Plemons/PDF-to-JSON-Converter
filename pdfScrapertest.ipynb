{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PyPDF2 as pdf2\n",
    "import textract\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = '/home/brett/Documents/Gitrepository/semesterProject/TestSpec.pdf'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdfFileObj = open(filename, 'rb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdfReader = pdf2.PdfFileReader(pdfFileObj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_pages = pdfReader.numPages\n",
    "count = 0\n",
    "text = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "while count < num_pages:\n",
    "    pageObj = pdfReader.getPage(0)\n",
    "    count += 1\n",
    "    text += pageObj.extractText()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "if text != \"\":\n",
    "    text = text\n",
    "else:\n",
    "    text = textract.process(filename, method=\"tesseract\", language=\"eng\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanText(x):\n",
    "    '''\n",
    "    This function takes the byte data extracted from scanned PDFs, and cleans it of all\n",
    "    unnessary data.\n",
    "    Requires re\n",
    "    Author: Brett Plemons\n",
    "    Date of writing: 20-Mar-19\n",
    "    '''\n",
    "    stringedText = str(x)\n",
    "    cleanText = stringedText.replace('\\n','')\n",
    "    splitText = re.split(r'\\W+', cleanText)\n",
    "    caseingText = [word.lower() for word in splitText]\n",
    "    cleanOne = [word for word in caseingText if word != 'n']\n",
    "    dexStop = cleanOne.index(\"od260\")\n",
    "    dexStart = cleanOne.index(\"sheet\")\n",
    "    clean = cleanOne[dexStart + 1:dexStop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['n21', 'feb', '2019', 'nsequence', 'lacz', 'rp', 'n5', 'gat', 'ctc', 'tac', 'cat', 'ggc', 'gca', 'cat', 'ttc', 'ccc', 'gaa', 'aag', 'tgc', '3', 'norder', 'no', '15775199', 'nref', 'no', '207335463', 'n25', 'nmole', 'dna', 'oligo', '36', 'bases', 'nproperties', 'amount', 'of', 'oligo', 'shipped', 'to', 'ntm', '50mm', 'nacl', '66', '8', 'xc2', 'xb0c', '11', '0', '32', '6', 'david', 'cook', 'ngc', 'content', '52', '8', 'd260', 'mmoles', 'kansas', 'state', 'university', 'biotechno', 'nmolecular', 'weight', '10', '965', '1', 'nnmoles']\n"
     ]
    }
   ],
   "source": [
    "print(cleanText(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
